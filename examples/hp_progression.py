import argparse
import logging
import pandas as pd
import seaborn as sns
from matplotlib import colors
from matplotlib import pyplot as plt
from mpl_toolkits.axes_grid1.inset_locator import inset_axes

sns.set()  # Set seaborn as default style
sns.set_theme()
sns.set_style("ticks")

def generate_cmap():
    """
    Generate the color map

    Returns
    -------
    np.array
        int array representing produced color map
    """
    scale_num = 3

    # Darker Starter base on RGB Color Code -
    cmap_color_prefix = sns.dark_palette(
        (0.28527278, 0.38012942, 0.82346855, 1), n_colors=10 * scale_num
    )
    sns.palplot(cmap_color_prefix)
    cmap_color_prefix = cmap_color_prefix[-6 * scale_num : -5 * scale_num]
    cmap_color_prefix = list(cmap_color_prefix)

    # # Configure color palette
    cmap_color = sns.color_palette("coolwarm", n_colors=20 * scale_num)
    cmap_color = list(cmap_color)
    cmap_color = cmap_color[: -12 * scale_num]
    cmap_color.extend([cmap_color[-1]] * 5 * scale_num)
    cmap_color_prefix.extend(cmap_color)
    cmap_color = tuple(cmap_color_prefix)
    sns.palplot(cmap_color)
    cmap = colors.ListedColormap(cmap_color, name="from_list")
    return cmap


if __name__ == "__main__":
    """
    python3 hp_progression.py
        --model_dir <model output data>
        --output_dir <>
    """
    parser = argparse.ArgumentParser(
        description="Generate hyperparameter progression figures"
    )
    parser.add_argument(
        "--model_dir",
        nargs=1,
        type=str,
        dest="model_dir",
        required=True,
        help="Directory for the trained model",
    )
    parser.add_argument(
        "--output_dir",
        nargs=1,
        type=str,
        dest="output_dir",
        required=True,
        help="Directory to save output figures",
    )
    parser.add_argument(
        "--verbose",
        dest="is_verbose",
        action="store_true",
        default=False,
        help="Display debug messages",
    )
    args = parser.parse_args()

    # Construct Logger (stdio)
    console_handler = logging.StreamHandler()
    formatter = None
    if args.is_verbose:
        console_handler.setLevel(logging.DEBUG)
        # time - service_name - level - thread name[calling function] - message
        formatter = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(funcName)s -  %(message)s"
        )
    else:
        console_handler.setLevel(logging.INFO)
        # time - service_name - level - message
        formatter = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
    console_handler.setFormatter(formatter)
    # Add the log configurations to the root logger
    logging.getLogger("").setLevel(logging.DEBUG)
    logging.getLogger("").addHandler(console_handler)
    # Get the logger instantiation
    logger = logging.getLogger("autolfads_hp_figs")
    logger.debug("Logger successfully initialized")
    logger.info("Runtime flags: " + str(vars(args)))

    model_dir = args.model_dir[0]
    output_dir = args.output_dir[0]

    logging.info("Load trial info (generation, metric etc.) from model_dir")
    # The label_info.csv is generated by standard kubeflow pipeline
    # The trial_info.csv is generated by customized log info in the source code
    label_info = pd.read_csv(f"{model_dir}/label_info.csv")
    trial_info = pd.read_csv(f"{model_dir}/trial_info.csv")
    trial_info_cp = pd.merge(label_info, trial_info, on="trialName")

    hp_list = [
        "lr",
        "do",
        "cd",
        "kl_ic",
        "kl_co",
        "l2_gen",
        "l2_con",
        "smth_nll_heldin",
        "smth_val_nll_heldin",
    ]
    hp_label = [
        "Learning Rate",
        "Dropout",
        "Coord. Dropout",
        "IC KL Weight",
        "CO KL Weight",
        "Gen. L2 Weight",
        "Con. L2 Weight",
        "Training NLL",
        "Validation NLL",
    ]

    logging.info("Plot the hyperparameter progression")
    hp_cmap = generate_cmap()
    plt.figure(figsize=(20, 18))
    for hp_idx, hp_i in enumerate(hp_list):
        # Hyper-parameter progression color coded with model performance
        ax = plt.subplot(3, 3, hp_idx + 1)
        sns.scatterplot(
            ax=ax,
            data=trial_info_cp,
            x="pbt.suggestion.katib.kubeflow.org/generation",
            y=hp_i,
            hue="smth_val_nll_heldin",
            palette=hp_cmap,
            hue_norm=colors.LogNorm(7.7e-2, 8.11e-2, clip=True),
            legend=False,
        )

        # Log-scale for all Hyper-parameter except Coordinated Dropout
        if hp_i != "cd":
            ax.set_yscale("log")

        # Plot the colorbar: performance evaluated on the validation set
        if hp_i == "smth_val_nll_heldin":
            hue_range = (
                min(trial_info_cp["smth_val_nll_heldin"]),
                max(trial_info_cp["smth_val_nll_heldin"]),
            )
            norm = colors.LogNorm(hue_range[0], hue_range[1], clip=True)
            sm = plt.cm.ScalarMappable(cmap=hp_cmap, norm=norm)
            sm.set_array([])
            axins = inset_axes(
                ax, width="120%", height="5%", loc="lower center", borderpad=-8
            )
            cb = ax.figure.colorbar(sm, cax=axins, orientation="horizontal")
            cb.ax.set_xlim([hue_range[0], hue_range[1]])
            cb.ax.invert_xaxis()

        ax.set_ylabel(hp_label[hp_idx], fontsize=18)
        if hp_idx <= 5:
            ax.set_xlabel("", fontsize=24)
        else:
            ax.set_xlabel("Generation", fontsize=18)

    sns.despine()
    plt.subplots_adjust(
        left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.5, hspace=0.3
    )

    plt.savefig(f"{output_dir}/hp_progression.pdf")
    plt.savefig(f"{output_dir}/hp_progression.png", transparent=True)
